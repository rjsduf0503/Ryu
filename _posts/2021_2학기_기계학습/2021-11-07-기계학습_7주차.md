---
layout: post
author: 류건열
title: 2021년 2학기 기계학습 7주차
categories: 기계학습
tags: [cnu, 기계학습, machine-learning, 과제]
---

- 7주차 과제 : SVM

  ![image](https://user-images.githubusercontent.com/34560965/140646570-6f8275f0-90e7-46f8-b3ed-35bd1b69fb07.png)
  ![image](https://user-images.githubusercontent.com/34560965/140646573-8869af06-72bf-49db-abb3-8c08032c6e54.png)
  ![image](https://user-images.githubusercontent.com/34560965/140646576-926df7ba-da4c-48de-94f0-be03571526a9.png)

  - 사용 언어 : python
  - 해결 날짜 : 2021-11-07
  - 코드 설명 :

    - Mnist data를 Sklearn 라이브러리를 이용하여 가져오고, 이 값은 총 7만개지만 train 데이터와 test 데이터가 섞여 있으므로 train_test_split을 사용하여 6:1로 나누어 주었다.
    - 처음에 스케일링을 하지 않고 c값만 변화시켜 정확도를 측정했더니 최대치가 0.85로 매우 낮았다. 성능을 높이기 위하여, 데이터 스케일링이 필요하다고 생각되어 QuantileTransformer 스케일러를 사용하여 데이터를 균등분포 시켰다.
    - 그 다음 최대 성능을 내는 C값을 찾기 위해 반복문을 사용하여 우선 0부터 10까지 1씩 늘려가며 (단 C는 양수여야 하기 때문에 0일 때는 0.1로 하였다.) 최적의 C값을 찾았고, 가장 클 때는 0.1이었다. 그 다음 최대일 때는 2로 그 차이가 미미하다고 생각되었기 때문에 C값을 0.1부터 2.9까지 0.1씩 늘려가며 다시 최적의 C값을 찾았다.
    - 이 때 훈련 및 성능 측정 모델로 SVC가 아닌 LinearSVC를 사용했는데, SVC를 사용하려니 몇시간 동안 훈련이 되지 않아 진행이 되지 않아서 어쩔 수 없이 LinearSVC를 사용했다.
    - 최적의 C값인 1.7로 성능을 측정한 결과 0.882의 정확도를 얻을 수 있었다. 아마 LInearSVC가 아닌 그냥 SVC를 사용했다면 더 높은 결과를 얻었을 수도 있을 것 같다.

  - 결과 :
    ![image](https://user-images.githubusercontent.com/34560965/140646579-66d56113-2585-4a9d-af46-35dc92d331dd.png)
    ![image](https://user-images.githubusercontent.com/34560965/140646584-3b288a9d-dc63-4120-ad6d-ab8ff807a932.png)
    ![image](https://user-images.githubusercontent.com/34560965/140646588-0133b184-0d9b-4563-9d71-b7bcdf1ed931.png)
    ![image](https://user-images.githubusercontent.com/34560965/140646590-adbedefe-ab7f-42b7-ae30-f0fa37c8eb21.png)
    ![image](https://user-images.githubusercontent.com/34560965/140646594-61fd5fe6-16f6-4f5a-a04b-3391f4165f1f.png)
    ![image](https://user-images.githubusercontent.com/34560965/140646602-57953dc1-d780-4eb8-8a79-9e5cc0c31dc2.png)

  - 코드

    ```python
    from sklearn.datasets import fetch_openml
    from sklearn.model_selection import train_test_split
    mnist = fetch_openml('mnist_784')

    train_input, test_input, train_target, test_target = train_test_split(mnist['data'],
                                                                        mnist['target'],
                                                                        test_size=(1/7),
                                                                        random_state=0)
    print(train_input.shape)


    from sklearn.preprocessing import QuantileTransformer

    scaler = QuantileTransformer()
    scaler.fit(train_input)
    train_input_scaled = scaler.transform(train_input)
    test_input_scaled = scaler.transform(test_input)


    from sklearn.svm import LinearSVC

    c_max = 0.1
    model = LinearSVC(C=c_max, random_state=0)
    model.fit(train_input_scaled, train_target)
    score_max = model.score(test_input_scaled, test_target)
    print(score_max)

    for i in range(1,11):
        model = LinearSVC(C=i, random_state=0)
        model.fit(train_input_scaled, train_target)
        temp_score = model.score(test_input_scaled, test_target)
        if score_max < temp_score:
            score_max = temp_score
            c_max = i
        print(temp_score)


    import numpy as np

    li = np.arange(0.1, 3, 0.1)
    for i in li:
        model = LinearSVC(C=i, random_state=0)
        model.fit(train_input_scaled, train_target)
        temp_score = model.score(test_input_scaled, test_target)
        if score_max < temp_score:
            score_max = temp_score
            c_max = i


    print("C값이 {c}일 때 Accuracy : {score}".format(c=round(c_max,1), score=score_max))
    ```
