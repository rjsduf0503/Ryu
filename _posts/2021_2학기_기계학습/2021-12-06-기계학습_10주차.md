---
######layout: post
author: 류건열
#title: Machine_Learning
---


- 10주차 과제 : MLP
 
    ![image](https://user-images.githubusercontent.com/34560965/144801387-fc812211-9e36-4472-9dc8-56c00dca2559.png)

    - 사용 언어 : python
    - 해결 날짜 : 2021-12-06
    - 코드 설명 : 
         
        - mnist 데이터를 다운 받아 불러온 후 1, 5, 8 클래스 데이터만 가지도록 재구성한다.
        - 그 후 데이터를 train set : validation set : test set = 7 : 1 : 2 가 되도록 나눈다.
        - 다음으로 validation을 set을 이용해 가장 좋은 모델을 가지도록, 노드의 개수를 10씩 늘려가며 solver의 옵션은 “adam, sgd”, activation function의 옵션은 “relu, logistic(sigmoid)”, 은닉층 수는 “2, 3”으로 검증한다. 총 경우의 수는 80개이다.
        - 그 결과, 노드의 개수=90, solver=adam, activation function=relu, 은닉층 개수=3일 때의 validation 정확도가 0.9938…으로 가장 좋은 것으로 나타났고, 이에 동일한 모델에 train + validation set을 학습하여 test set으로 분류 정확도를 측정한 결과 0.99000…으로 약 99%의 분류 정확도를 가진다.





    - 결과 : 
        ![image](https://user-images.githubusercontent.com/34560965/144801390-03421e16-a86f-45ab-9c79-c05d34061e1a.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801398-f9c8258a-2907-426d-9c06-f04d8c47b381.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801403-7d3ce6a8-97fc-4d04-8f75-d9c25cadc725.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801407-08e4f9a3-42bf-4603-8a19-0f9d94e7c6a1.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801409-8f821ee2-036a-4c98-bde4-626d3d9026a7.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801413-d0a8225d-b618-4d27-a387-8e23e76e4dee.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801417-28380a60-7b2c-4cc8-9a5b-6269e07124aa.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801425-5a328c51-d287-4337-93e6-ecb833d5445c.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801427-52fb9029-6e88-47c4-9ae7-3130e51f00cb.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801440-43751840-6708-4b01-84e4-28390053cf32.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801449-c22bdba9-9dcb-4666-8890-8567633ad1e9.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801451-e1fc1024-429e-4512-a438-0e33e1afd81f.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801459-8f3671cc-5c2f-4b88-aa24-f03be43da3f2.png)
        ![image](https://user-images.githubusercontent.com/34560965/144801468-f988220d-b72d-4c3c-a916-67a2180584de.png)


    - 코드	

        ```python
        from sklearn.datasets import fetch_openml

        mnist = fetch_openml('mnist_784')

        import numpy as np
        from sklearn.model_selection import train_test_split

        X = mnist.data
        Y = mnist.target

        # 1,5,8 클래스 데이터만 가지도록 구성
        data = X[np.logical_or(np.logical_or(Y=='1', Y=='5'), Y=='8')]
        target = Y[np.logical_or(np.logical_or(Y=='1', Y=='5'), Y=='8')]

        # train : validation : test = 7 : 1 : 2 가 되도록 나눔
        train_x, test_input, train_y, test_target = train_test_split(data,
                                                                    target,
                                                                    test_size=0.2,
                                                                    random_state=0)

        train_input, val_input, train_target, val_target = train_test_split(train_x, 
                                                        train_y, 
                                                        test_size=0.125, 
                                                        random_state=0)


        from sklearn.neural_network import MLPClassifier
        import mglearn

        for i in range (0, 101, 10):
            j = i
            if i == 0:
                j = i + 1
                
            mlp = MLPClassifier(solver='adam', activation='relu', random_state=0, hidden_layer_sizes=[j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='adam', activation='relu', random_state=0, hidden_layer_sizes=[j, j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='adam', activation='logistic', random_state=0, hidden_layer_sizes=[j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='adam', activation='logistic', random_state=0, hidden_layer_sizes=[j, j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))
            
            mlp = MLPClassifier(solver='sgd', activation='relu', random_state=0, hidden_layer_sizes=[j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='sgd', activation='relu', random_state=0, hidden_layer_sizes=[j, j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='sgd', activation='logistic', random_state=0, hidden_layer_sizes=[j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))

            mlp = MLPClassifier(solver='sgd', activation='logistic', random_state=0, hidden_layer_sizes=[j, j, j])
            mlp.fit(train_input, train_target)
            print("노드의 개수가 {node}일 때 검증 : {score}".format(node = j, score = mlp.score(val_input, val_target)))


        final_mlp = MLPClassifier(solver='adam', activation='relu', random_state=0, hidden_layer_sizes=[90, 90, 90])
        final_mlp.fit(train_x, train_y)
        print(final_mlp.score(test_input, test_target))


        ```
