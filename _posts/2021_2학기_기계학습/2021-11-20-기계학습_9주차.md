---
layout: post
author: 류건열
title: 2021년 2학기 기계학습 9주차
categories: 기계학습
tags: [cnu, 기계학습, machine-learning, 과제]
---

- 9주차 과제 : Text data 처리 2

  ![image](https://user-images.githubusercontent.com/34560965/142651979-c6c532d1-536f-4199-b596-7aac58574f35.png)

  - 사용 언어 : python
  - 해결 날짜 : 2021-11-20
  - 코드 설명 :

    - bbcsport 데이터를 다운 받아 불러온 후 데이터 인코딩 방식 변경 및 전처리 과정을 진행한다.
    - 그 후 Tfidvectorizer를 이용해 불용어 처리와 tf-idf, L2-normalization을 적용하고 5-cross-validation을 이용해 분류 정확도를 측정한다. 이 때 분류 정확도의 평균은 0.9755837470123184로 측정되었다.
    - 다음으로 PCA 사용을 위해 x값을 todense()함수로 행렬로 변환 시켜 주고, 각 2차원과 10차원으로 감소시킨다. 이 때 마찬가지로 5-cross-validation을 이용해 분류 정확도를 측정한다. 2차원으로 감소시킬 때의 분류 정확도의 평균은 0.8656554513697371로 가장 낮았고, 10차원으로 감소시킬 때의 분류 정확도의 평균은 0.9701415701415701로 차원 감소 전 분류 정확도와 유사했다.

  - 결과 :
    ![image](https://user-images.githubusercontent.com/34560965/142652023-9bdbf39e-8461-41a1-a288-8c94942588cf.png)
    ![image](https://user-images.githubusercontent.com/34560965/142652041-02eb54f5-81d6-424c-87fb-34cf7507f55c.png)
    ![image](https://user-images.githubusercontent.com/34560965/142652056-ab2d7c21-7108-4683-a361-5381389dd39c.png)

  - 코드

    ```python
    import chardet
    from sklearn.datasets import load_files

    files = load_files('./bbcsport/')
    x, y = files.data, files.target

    #데이터 인코딩 방식 변경
    for i in range(len(x)):
        if(chardet.detect(x[i])!='utf-8'):
            x[i] = x[i].decode(chardet.detect(x[i])['encoding']).encode('utf8')

    #데이터 전처리
    x = [doc.replace(b'',b'') for doc in x]
    x = [doc.replace(b'\n',b' ') for doc in x]

    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.model_selection import KFold, cross_val_score

    #기존 데이터
    knn = KNeighborsClassifier(n_neighbors=1)
    kfold = KFold(n_splits=5, shuffle=True, random_state=0)

    vectorizer = TfidfVectorizer(input=x, stop_words = 'english', norm='l2')
    x_transformed = vectorizer.fit_transform(x)
    score = cross_val_score(knn, x_transformed, y, cv=kfold)
    score_mean = score.mean()

    from sklearn.decomposition import PCA
    #PCA 사용을 위해 행렬로 변환
    x_dense = x_transformed.todense()

    #2차원으로 감소
    pca_2 = PCA(n_components=2)
    pca_2.fit(x_dense)
    x_pca_2 = pca_2.transform(x_dense)
    score_2 = cross_val_score(knn, x_pca_2, y, cv=kfold)
    score_2_mean = score_2.mean()

    #10차원으로 감소
    pca_10 = PCA(n_components=10)
    pca_10.fit(x_dense)
    x_pca_10 = pca_10.transform(x_dense)
    score_10 = cross_val_score(knn, x_pca_10, y, cv=kfold)
    score_10_mean = score_10.mean()

    print("기존 데이터 크기 : {size}".format(size=x_transformed.shape))
    print("데이터 차원 2로 감소시킨 데이터 크기 : {size}".format(size=x_pca_2.shape))
    print("데이터 차원 10으로 감소시킨 데이터 크기 : {size}".format(size=x_pca_10.shape))

    print("기존 데이터 분류 정확도 : {score}".format(score=score))
    print("변환되는 데이터 차원이 2일 때 분류 정확도 : {score}".format(score=score_2))
    print("변환되는 데이터 차원이 10일 때 분류 정확도 : {score}".format(score=score_10))

    print("기존 데이터 분류 정확도의 평균 : {score}".format(score=score_mean))
    print("변환되는 데이터 차원이 2일 때 분류 정확도의 평균 : {score}".format(score=score_2_mean))
    print("변환되는 데이터 차원이 10일 때 분류 정확도의 평균 : {score}".format(score=score_10_mean))
    ```
